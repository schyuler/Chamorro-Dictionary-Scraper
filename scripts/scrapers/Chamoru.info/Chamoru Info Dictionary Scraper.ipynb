{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chamoru.Info Dictionary Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About This Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script scrapes and processes Chamorro dictionary data from chamoru.info as part of a broader effort to collect and analyze online Chamorro language resources. The goal is to support language revitalization by enabling further linguistic analysis and the development of digital learning tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Schyuler Lujan <br>\n",
    "**Date Completed:** 24-November-2020 <br>\n",
    "**Date Updated:** 13-May-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for webscraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Import libraries for exporting data\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will create the URLs that contain the data we want to scrape. The dictionary website at Chamoru.info has a predictable structure, allowing us to create each URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url():\n",
    "    \"\"\"\n",
    "    Creates a list of all the urls for every page of the online dictionary on the chamoru.info website\n",
    "    \"\"\"\n",
    "    # Create dictionary of letters and page ranges\n",
    "    letters = {'A': [1, 7], '%C3%85': [1, 22], 'B': [1, 19], 'CH': [1, 10], 'D': [1, 15], 'E': [1, 11], 'F': [1, 13], \n",
    "               'G': [1, 13], 'H': [1, 10], 'I': [1, 7], 'K': [1, 24], 'L': [1, 11], 'M': [1, 22], 'N': [1, 10], \n",
    "               '%C3%91': [1, 2], 'NG': [1,1], 'O': [1, 4], 'P': [1, 20], 'R': [1, 5], 'S': [1, 17], 'T': [1, 19], \n",
    "               'U': [1, 3], 'Y': [1, 3]}\n",
    "    \n",
    "    #letters = {'A': [1, 7]}\n",
    "\n",
    "    # Create variables for constructing web addresses\n",
    "    address1 = 'http://www.chamoru.info/dictionary/display.php?action=search&by='\n",
    "    address2 = '&nr_page='\n",
    "    \n",
    "    # Create web addresses for all letters and append them to a list\n",
    "    web_addresses = [] # initialize list\n",
    "    \n",
    "    for key in letters:\n",
    "        head = address1+key+address2\n",
    "        start = letters[key][0]\n",
    "        end = letters[key][1]+1\n",
    "    \n",
    "        # loop thru key values in letters to append the appropriate page number\n",
    "        for i in range(start, end):\n",
    "            i = str(i) # convert int to string for concatenation\n",
    "            web_addresses.append(head+i)\n",
    "    \n",
    "    return web_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the URLS\n",
    "urls = create_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export URLs to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Python list to dataframe\n",
    "urls_df = pd.DataFrame(urls)\n",
    "\n",
    "# Define folder name and filename\n",
    "base_path = #\"PUT_YOUR_ABSOLUTE_PATH_HERE\"\n",
    "folder_path = base_path + \"Chamorro-Dictionary-Scraper/exports/csv\"\n",
    "file_name = \"chamoru_info_urls.csv\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Export to CSV\n",
    "urls_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Dictionary Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will navigate to each of the URLs created in the previous section and scrape the dictionary entries from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary_content(addresses):\n",
    "    \"\"\"\n",
    "    Gets the contents of the websites with the urls generated from create_url and parses the contents\n",
    "    \"\"\"\n",
    "    # initialize the dictionary for storing all terms and definitions\n",
    "    dictionary_data = {}\n",
    "\n",
    "    current_term = None\n",
    "    current_def = None\n",
    "\n",
    "    for url in addresses:\n",
    "\n",
    "        # Go to the url and parse the html\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        response.encoding = response.apparent_encoding\n",
    "    \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "        # Find the terms and definitions, and add them to the dictionary\n",
    "        for tag in soup.body.descendants:\n",
    "            if tag.name == 'dd':\n",
    "                current_term = tag.get_text(strip=True)\n",
    "            elif tag.name == 'dt':\n",
    "                current_def = tag.get_text(strip=True)\n",
    "                if current_term and current_def:\n",
    "                    dictionary_data[current_term] = current_def\n",
    "        \n",
    "    return dictionary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dictionary contents\n",
    "dictionary_contents = get_dictionary_content(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Dictionary Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary_contents to a regular dictionary before exporting\n",
    "dictionary_dict = {word: definition for word, definition in dictionary_contents.items()}\n",
    "\n",
    "# Define folder name and filename\n",
    "folder_path = base_path +\"Chamorro-Dictionary-Scraper/exports/json\"\n",
    "file_name = \"chamoru_info_dictionary.json\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Verify the folder exists; if it doesnt, create it\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Write dictionary_contents to JSON\n",
    "with open(file_path, mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(dictionary_dict, file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary_contents to dataframe\n",
    "dictionary_df = pd.DataFrame(list(dictionary_contents.items()), columns=[\"term\", \"definition\"])\n",
    "\n",
    "# Define folder and filename\n",
    "folder_path = base_path +\"Chamorro-Dictionary-Scraper/exports/csv\"\n",
    "file_name = \"chamoru_info_dictionary.csv\"\n",
    "file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "# Export dataframe to CSV\n",
    "dictionary_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create a Dictionary in Python || Web Scraping\n",
    "\n",
    "https://www.youtube.com/watch?v=atDgcb-ImMo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
